# Self-Host LLM

Learning to self-host LLM on local or cloud

- [Reddit - LocalLlama](https://www.reddit.com/r/LocalLLaMA/)

## LLM Operations and Support Tools

> List support by LangChain: [LLMs | ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/integrations/llms/#features-natively-supported)

### Ollama

> Easier to run

- [Ollama](https://ollama.com/)
- [ollama/ollama: Get up and running with Llama 2, Mistral, Gemma, and other large language models.](https://github.com/ollama/ollama)
- [Ollama | ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/integrations/llms/ollama/)
- [ChatOllama | ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/integrations/chat/ollama/)
- [Ollama and LangChain: Run LLMs locally | by Abonia Sojasingarayar | Feb, 2024 | Medium](https://medium.com/@abonia/ollama-and-langchain-run-llms-locally-900931914a46)
- [Windows preview ¬∑ Ollama Blog](https://ollama.com/blog/windows-preview)

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### llama.cpp

> Launch earlier

- [ggerganov/llama.cpp: LLM inference in C/C++](https://github.com/ggerganov/llama.cpp)
- [Llama.cpp | ü¶úÔ∏èüîó LangChain](https://python.langchain.com/docs/integrations/llms/llamacpp/)
- [abetlen/llama-cpp-python: Python bindings for llama.cpp](https://github.com/abetlen/llama-cpp-python)

### alpaca.cpp (not maintaining)

- [antimatter15/alpaca.cpp: Locally run an Instruction-Tuned Chat-Style LLM](https://github.com/antimatter15/alpaca.cpp)

## Other

### Free API

- [aurora-develop/aurora](https://github.com/aurora-develop/aurora)
- [xqdoo00o/ChatGPT-to-API: Scalable unofficial ChatGPT API for production.](https://github.com/xqdoo00o/ChatGPT-to-API)
  - [acheong08/ChatGPT-to-API: Scalable unofficial ChatGPT API for production.](https://github.com/acheong08/ChatGPT-to-API) (archived)
- [xtekky/gpt4free: The official gpt4free repository | various collection of powerful language models](https://github.com/xtekky/gpt4free)

### CLI Tools

- [taketwo/llm-ollama: LLM plugin providing access to local Ollama models using HTTP API](https://github.com/taketwo/llm-ollama)
- [LLM: A CLI utility and Python library for interacting with Large Language Models](https://llm.datasette.io/en/stable/)
